# Лабораторная работа №3: Оркестрация ETL-процессов с Apache Airflow

Дисциплина: Анализ больших данных и рыночных тенденций

Направление: Бизнес-информатика (магистратура)

Вариант 25

ФИО студента: Шитов Данила Олегович

ФИО преподователя: Босенко Тимур Муртазович

## Бизнес-задача: Анализ популярности артистов в жанре Rock
### Описание проблемы
Компания-стриминговый сервис хочет автоматически определять, какие артисты наиболее популярны в конкретном жанре. Это помогает в формировании плейлистов, маркетинговых кампаний и рекомендаций пользователям.
### Бизнес-ценность решения
-  **Автоматизация аналитики** — ежедневный расчет топ-артистов без участия аналитика
-  **Выявление лидеров** — быстрое определение самых прослушиваемых исполнителей
-  **Принятие решений на основе данных** — объективная оценка популярности артистов
- ⏰ **Экономия времени** — автоматическая обработка данных из разных источников
-  **Своевременное уведомление** — автоматическая отправка отчетов заинтересованным лицам

**Бизнес-логика расчета:**
1. Отфильтровать треки по жанру "Rock"
2. Подсчитать количество прослушиваний для каждого артиста
3. Вывести топ-5 артистов с наибольшим количеством прослушиваний

### Бизнес-ценность решения
- 📊 **Автоматизация аналитики** - ежедневный расчет ключевых метрик без участия аналитика
- 🎯 **Выявление проблемных категорий** - быстрое определение приложений с низким удержанием
- 📈 **Принятие решений на основе данных** - объективная оценка успешности продуктов
- ⏰ **Экономия времени** - автоматическая обработка данных из разных источников
- 📧 **Своевременное уведомление** - автоматическая отправка отчетов заинтересованным лицам

### Вариант задания №25: Музыкальные треки — Топ-5 артистов в жанре Rock

**Исходные данные:**
- **Файл 1 (CSV)**: Треки — `track_id`, `artist_id`, `genre`
- **Файл 2 (Excel)**: Прослушивания — `track_id`, `user_id`
- **Файл 3 (JSON)**: Артисты — `artist_id`, `artist_name`

**Бизнес-логика расчета:**
```
Retention Rate = (Installs - Uninstalls) / Installs × 100%
Churn Rate = Uninstalls / Installs × 100%
Retained Users = Installs - Uninstalls
```

**Ожидаемый результат:** Текстовый отчёт и CSV-файл с топ-5 артистов в жанре Rock.

## Архитектура решения

### Общая схема системы

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           DOCKER COMPOSE ENVIRONMENT                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │   PostgreSQL    │    │   Apache        │    │    MailHog      │         │
│  │   Database      │    │   Airflow       │    │  Email Service  │         │
│  │                 │    │                 │    │                 │         │
│  │ Port: 5432      │    │ ┌─────────────┐ │    │ SMTP: 1025      │         │
│  │ User: airflow   │◄───┤ │ Webserver   │ │    │ Web: 8025       │         │
│  │ DB: airflow     │    │ │ Port: 8080  │ │    │                 │         │
│  │                 │    │ └─────────────┘ │    │                 │         │
│  └─────────────────┘    │ ┌─────────────┐ │    └─────────────────┘         │
│                         │ │ Scheduler   │ │                                │
│                         │ │             │ │                                │
│                         │ └─────────────┘ │                                │
│                         └─────────────────┘                                │
│                                   │                                        │
│                         ┌─────────▼─────────┐                              │
│                         │   DAGs Volume     │                              │
│                         │   ./dags:/opt/    │                              │
│                         │   airflow/dags    │                              │
│                         └───────────────────┘                              │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                              HOST SYSTEM                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐         │
│  │   Data Files    │    │   DAG Files     │    │  Result Files   │         │
│  │                 │    │                 │    │                 │         │
│  │ tracks.csv      │    │ music_top_roc   │    │ *.db (SQLite)   │         │
│  │ listens.xlsx    │    │_artists_analy   │    │ *.txt (Reports) │         │
│  │ artists.json    │    │    sis.py       │    │ *.csv (Data)    │         │
│  └─────────────────┘    └─────────────────┘    └─────────────────┘         │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        Web Interfaces                              │   │
│  │                                                                     │   │
│  │  http://localhost:8080  - Apache Airflow UI                        │   │
│  │  http://localhost:8025  - MailHog Web Interface                    │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

### ETL-процесс для анализа удержания пользователей

```
                    EXTRACT PHASE (Параллельно)
┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
│  extract_apps   │  │extract_installs │  │extract_uninstalls│
│                 │  │                 │  │                 │
│ tracks.csv      │  │ listens .xlsx   │  │ artists.json    │
│ ┌─────────────┐ │  │ ┌─────────────┐ │  │ ┌─────────────┐ │
│ │app_id       │ │  │ │app_id       │ │  │ │app_id       │ │
│ │category     │ │  │ │installs_    │ │  │ │uninstalls_  │ │
│ │             │ │  │ │count        │ │  │ │count        │ │
│ └─────────────┘ │  │ └─────────────┘ │  │ └─────────────┘ │
└─────────────────┘  └─────────────────┘  └─────────────────┘
         │                     │                     │
         └─────────────────────┼─────────────────────┘
                               │
                    TRANSFORM PHASE
                ┌─────────────────┐
                │ transform_data  │
                │                 │
                │ 1. JOIN данные  │
                │ 2. GROUP BY     │
                │    category     │
                │ 3. CALCULATE    │
                │    retention    │
                │    metrics      │
                └─────────────────┘
                         │
                    LOAD PHASE
                ┌─────────────────┐
                │load_to_database │
                │                 │
                │ SQLite DB       │
                │ retention_      │
                │ analysis table  │
                └─────────────────┘
                         │
                 REPORTING PHASE
                ┌─────────────────┐
                │generate_report  │
                │                 │
                │ TXT Report      │
                │ CSV Data Export │
                └─────────────────┘
                         │
               NOTIFICATION PHASE
                ┌─────────────────┐
                │send_email_      │
                │notification     │
                │                 │
                │ HTML Email +    │
                │ File Attachments│
                └─────────────────┘
```

## Технический стек

| Компонент | Технология | Назначение |
|-----------|------------|------------|
| **Оркестрация** | Apache Airflow 2.5.0 | Управление ETL-процессами |
| **Контейнеризация** | Docker + Docker Compose | Изоляция и развертывание |
| **База данных (Airflow)** | PostgreSQL 12 | Метаданные Airflow |
| **База данных (Результаты)** | SQLite | Хранение результатов анализа |
| **Обработка данных** | Python 3.8 + Pandas | ETL-логика и трансформации |
| **Работа с Excel** | openpyxl | Чтение Excel файлов |
| **Email-тестирование** | MailHog | Тестирование email-уведомлений |
| **Веб-интерфейс** | Airflow WebUI | Мониторинг и управление |

## Пошаговая инструкция запуска

### Шаг 1: Подготовка окружения

1. **Клонирование проекта**:
   ```bash
   git clone https://github.com/BosenkoTM/DCCAS.git
   cd DCCAS/lw_03
   ```

2. **Запуск всех сервисов**:
   ```bash
   sudo docker compose up -d
   ```

3. **Проверка статуса контейнеров**:
   ```bash
   sudo docker ps
   ```
   Должны быть запущены: `webserver`, `scheduler`, `postgres`, `mailhog`

### Шаг 2: Работа с Apache Airflow

#### Доступ к веб-интерфейсу
- **URL**: http://localhost:8080
- **Логин**: admin
- **Пароль**: admin

#### Что смотреть в Airflow UI:

1. **Главная страница (DAGs)**:
   - Найдите DAG `music_top_rock_artists_analysis`
   - Убедитесь, что он включен (переключатель слева должен быть активен)

2. **Запуск DAG**:
   - Кликните на название DAG
   - Нажмите кнопку "Trigger DAG" (▶️) для ручного запуска
   - Или дождитесь автоматического запуска по расписанию

3. **Мониторинг выполнения**:
   - **Graph View** - визуальное представление задач и их зависимостей
   - **Tree View** - история запусков DAG
   - **Gantt View** - временная диаграмма выполнения задач

4. **Статусы задач**:
   - 🟢 **Success** - задача выполнена успешно
   - 🔴 **Failed** - задача завершилась с ошибкой
   - 🟡 **Running** - задача выполняется
   - ⚪ **Queued** - задача в очереди на выполнение

5. **Просмотр логов**:
   - Кликните на задачу в Graph View
   - Выберите "View Log" для просмотра детальных логов

### Шаг 3: Проверка email-уведомлений в MailHog

#### Доступ к MailHog
- **URL**: http://localhost:8025

#### Что смотреть в MailHog:

1. **После успешного выполнения DAG** появится письмо:
   - **От**: airflow@example.com
   - **Кому**: test@example.com
   - **Тема**: "📊 Анализ коэффициента удержания мобильных приложений - Результаты"

2. **Содержимое письма**:
   - 📊 HTML-таблица с результатами анализа по категориям
   - 📎 Прикрепленные файлы:
     - `retention_analysis_report.txt` - подробный отчет
     - `retention_analysis_data.csv` - данные в формате CSV

3. **Интерфейс MailHog**:
   ```
   ┌─────────────────────────────────────────┐
   │  MailHog Web Interface                  │
   │  http://localhost:8025                  │
   ├─────────────────────────────────────────┤
   │  📧 Inbox (1)                          │
   │  ┌─────────────────────────────────────┐ │
   │  │ ✉️  Анализ коэффициента удержания   │ │
   │  │     airflow@example.com             │ │
   │  │     2024-10-02 15:30:45            │ │
   │  └─────────────────────────────────────┘ │
   │                                         │
   │  📄 Message Preview:                    │
   │  HTML-таблица с результатами           │
   │  📎 Attachments: 2 files               │
   └─────────────────────────────────────────┘
   ```

### Шаг 4: Проверка результатов анализа

#### Использование скрипта check_results.py

1. **Установка зависимостей**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Проверка результатов в базе данных**:
   ```bash
   python3 check_results.py
   ```
   Скрипт автоматически:
   - Найдет контейнер scheduler
   - Скопирует базу данных SQLite из контейнера
   - Покажет результаты анализа в удобном формате

3. **Копирование файлов результатов**:
   ```bash
   python3 check_results.py --files
   ```
   Скопирует из контейнера:
   - `retention_analysis_report.txt` - подробный отчет
   - `retention_analysis_data.csv` - данные для Excel

4. **Справка по скрипту**:
   ```bash
   python3 check_results.py --help
   ```

#### Вывод результатов:

ТОП-5 САМЫХ ПРОСЛУШИВАЕМЫХ АРТИСТОВ В ЖАНРЕ ROCK
==================================================
Дата анализа: 2025-11-07 20:52:03
Общее количество артистов в выборке: 4

Рейтинг:
1. Queen — 380 прослушиваний
2. AC/DC — 290 прослушиваний
3. Metallica — 290 прослушиваний
4. Led Zeppelin — 120 прослушиваний

### Шаг 5: Остановка сервисов

```bash
sudo docker compose down
```

## Полная очистка проекта

### Автоматическая очистка с помощью cleanup.sh

Используйте готовый скрипт для полной очистки Docker окружения:

```bash
# Сделать скрипт исполняемым
chmod +x cleanup.sh

# Запустить полную очистку
sudo ./cleanup.sh
```

**Что делает скрипт cleanup.sh:**
- ✅ Останавливает все контейнеры
- ✅ Удаляет все контейнеры проекта
- ✅ Удаляет образы проекта (Apache Airflow, PostgreSQL, MailHog)
- ✅ Удаляет все тома и сети Docker
- ✅ Очищает систему Docker от неиспользуемых ресурсов
- ✅ Удаляет локальные файлы результатов
- ✅ Показывает подробную статистику очистки
- ✅ Запрашивает подтверждение перед выполнением

**Использование:**
```bash
sudo ./cleanup.sh
```

Скрипт интерактивный и безопасный - запросит подтверждение перед удалением данных.

## Структура проекта

```
lw_03/
├── dags/
│   ├── data/                          # Исходные данные
│   │   ├── tracks.csv                   # Приложения и категории (20 записей)
│   │   ├── listens.xlsx              # Данные об установках (20 записей)
│   │   └── artist.json            # Данные об удалениях (20 записей)
│   ├── 01_umbrella.py                 # Пример DAG (оригинальный)
│   ├── aggreg.py                      # Пример агрегации (оригинальный)
│   └── music_top_rock_artists_analysis.py   # DAG для варианта №25 ⭐
├── docker-compose.yml                 # Конфигурация Docker Compose
├── requirements.txt                   # Зависимости Python
├── check_results.py                   # Скрипт для проверки результатов 🔍
├── cleanup.sh                         # Скрипт полной очистки 🧹
└── README.md                          # Данная инструкция
```

## Выводы

### Технические достижения
1. ✅ **Успешно реализован полный ETL-процесс** с использованием Apache Airflow
2. ✅ **Автоматизирована обработка разнородных данных** (CSV, Excel, JSON)
3. ✅ **Настроена оркестрация задач** с правильными зависимостями и параллельным выполнением
4. ✅ **Реализованы уведомления** с отправкой результатов по email
5. ✅ **Обеспечена отказоустойчивость** с обработкой ошибок и повторными попытками

### Бизнес-результаты
1. 📊 **Автоматизирован расчет ключевых метрик** удержания пользователей
2. 🎯 **Выявлены категории приложений** с различными показателями эффективности
3. 📈 **Созданы рекомендации** для улучшения продуктовой стратегии
4. ⏰ **Сокращено время** на подготовку аналитических отчетов
5. 📧 **Обеспечена своевременная доставка** результатов заинтересованным лицам

### Практические навыки
- Проектирование и реализация ETL-процессов
- Работа с Apache Airflow (DAGs, операторы, зависимости)
- Контейнеризация приложений с Docker Compose
- Обработка данных с помощью Python и Pandas
- Настройка email-уведомлений и мониторинга
- Работа с различными форматами данных (CSV, Excel, JSON, SQLite)

### Возможности для развития
- Добавление более сложных аналитических метрик
- Интеграция с реальными источниками данных (API, базы данных)
- Настройка алертов при критических изменениях показателей
- Создание дашбордов для визуализации результатов
- Масштабирование на кластер Airflow для больших объемов данных

Данная лабораторная работа демонстрирует полный цикл создания производственного ETL-решения с использованием современных инструментов оркестрации данных.
